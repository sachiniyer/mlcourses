#+TAGS: CIL


* A Theoretical Study on Solving Continual Learning
** Review
*** Info
- *Arxiv:* https://arxiv.org/abs/2211.02633
- *Authors:* Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, Bing Liu
- *Date:* Nov 2022
*** Problem Being Solved?
The paper aims to prove that OOD is important to the Continual Learning Problem. There are two types of Continual Learning, Class Incremental Learning (CIL) and Task Incremental Learning (TIL). TIL is essentially the same thing as Within-Task Prediction, so it is not considered strongly in the paper. Instead the paper focuses on a way to improve CIL.

The paper shows that a good Within-Task Prediction (WP) and Task-ID Prediction (TP) is necessary and sufficient for a good CIL. Additionally, Out of Distribution detection (OOD) + TP is necessary and sufficient for a good WP.
#+begin_src mermaid :file images/continual-learning-theoreticalp1.png
stateDiagram-v2
   CL: Continual Learning (CL)
   CIL: Class Incremental Learning (CIL)
   TIL: Task Incremental Learning (TIL)
   WP: Within-Task Prediction (WP)
   TP: Task-Id Prediction (TP)
   OOD: Out of Distribution Detection (OOD)
   CL --> CIL

   CL --> TIL
   CIL --> WP
   TIL --> WP

   CIL --> TP
   WP --> TP
   WP --> OOD
#+end_src

#+RESULTS:
[[file:images/continual-learning-theoreticalp1.png]]

*** What is an overview of the method?
The paper has two parts, a theoretical foundation for why this structure exists as it does. An experimental portion where CIL algorithms are paired with good OOD detection algorithms and the performance is show to increase. I'll skip the theoretical foundations (to hard to synthesize into something that can be explained easily).
*** What are the metrics of success?
- Average Classification Accuracy: How accurate is the method over all the classes after learning the last class
- Average AUC (Area Under the ROC Curve): [[https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/][ROC Curve Doc]]. Basically for a given task, measuring the AUC (binary being In Distribution and Out of Distribution) and then taking the average of that number across all of the tasks.
*** What are the key innovations over prior work?
1. Providing a solid theoretical foundation for why OOD detection matters
2. Backing up that theoretical foundation with emperical results that also prove that OOD detection matters
*** What are the key results?
They show that a good OOD detection algorithm (e.g. ODIN or CSI) can significantly improve the accuracy of a CIL model (e.g. HAT or Sup). They show that the addition of CSI to HAT or Sup outperform the baselines by a large margin.
*** How might this work have long term impact?
- Implication for regularization and replay methods: It is important to learn the OOD detection and minimize for catastrophic forgetting together.
- Implication for open-world learning: New tasks can continually be discovered through OOD detection and learned, potentially allowing for self-supervised learning.
- WP and TP/OOD need to be optimized jointly to ensure that OOD does not affect previous tasks
** Questions
N/A

* Detailed Review
** O Abstract
There are two types of Continual Learning, Class Incremental Learning (CIL) and Task Incremental Learning (TIL). The main problem with both is catastrophic forgetting (CF).
- TIL: Catastrophic forgetting is mostly solved
- CIL: Catastrophic forgetting is still an issue due to inter-task class separation
  - Within-Task Prediction (WIP): Effectively the same as TIL
  - Task-Id Prediction (TIP): This is main problem, and is correlated with the Out-Of-Distribution (OOD) technique

This paper also shows that WIP and TIP are /necessary and sufficient/ for good CIL performance.
** 1 Introduction
CIL: The learning process builds a single classifier for all the tasks/classes learned so far. Any test instance from any class can be presented for classification. No task information (e.g. task id) will be presented at test time.
*** Class Incremental Learning
- $$D_k = (x_k^i, y_k^i)_{i=1}^{n_k}$$ describes the training dataset for each task $$k$$
