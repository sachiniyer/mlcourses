#+TAGS: CIL


* Class Incremental Learning via Likelihood Ratio Based Task Prediction
*QUESTIONS DESCRIBED IN DETAILED REVIEW*
** Review
*** Info
- *Arxiv:* https://arxiv.org/abs/2309.15048
- *Authors:* Haowei Lin, Yijia Shao, Weinan Qian, Ningxin Pan, Yiduo Guo, Bing Liu
- *Date:* Sept 2023
*** Problem Being Solved?
*** What is an overview of the method?
*** What are the metrics of success?
*** What are the key innovations over prior work?
*** What are the key results?
*** How might this work have long term impact?
** Questions
*** TODO Read through Appendix and add more information in the detailed description
*** TODO Read a bit more through the derivation of the energy function
* Detailed Review
** 1 Introduction
This paper is focusing on CIL, not TIL (look to [[./cl-theoretical.org]] for the definitions). The main challenge is catastrophic forgetting (again go [[./cl-theoretical.org]] for the definition). The main challenge with catastrophic forgetting is /inter-task class separation/ (look to [[./learnability-cl.org]] for the definition). The new technique that is being proposed is to combine an OOD model with a CIL model to increase that class id prediction. The final prediction is the product of /task-id prediction/ and /within-task prediction/.
*** Why not traditional OOD detectors?
Traditional OOD detectors are not optimal, because they don't exploit the CIL use case. The new method is broken down into the following:
1. A new method to train each task model
2. a new method to do task-id prediction. This is formulated as an estimation of $\mathbf{P}(t|x)$ , which is a binary selection problem between two events: whether $x$ belongs to $t$ or if x belongs to $t^c$. $t^c$ is computed as all the tasks that are not the task being selected upon. Essentially $t^c = U_{CIL} - \{t\}$ where $U_{CIL} = \{1, 2, \cdots, T\}$

The main difference between this method and OOD detection is that usually we are estimating whether a test sample belongs to any of the classes in $U_{IND}$, or belongs to $U_{OOD}$ (which then contains all the classes in the world). This method instead looks at the likelihood ration of $P_t$ and $P_{t^c}$, based off the previous replay data (and creating a distribution $U_{CIL}$). This allow us to have better estimates than trying to classify it into some certain subset of classes, or all classes as a whole.

The proposed system TPL (Task-id Prediction based on Likelihood Ratio) uses the learned masks from HAT to overcome CF in the main TIL step. However, the head for each of tasks is instead a model that allows for task-id prediction. Each of the logits are fed into that model to figure out which task it belongs to. Using and not using a pre-trained model TPL outperforms the strong baselines (almost no forgetting or performance deterioration - also the forgetting rate is not correct for CIL).
** 2 Related Work
*** OOD Detection
The maximum softmax probability is the traditional OOD score. Another traditional method is to use Mahalanobis distance and KNN to find the distance from the test sample to the training data/IND distribution (this is also what CIDER does). This new method is different than the previous OOD methods.
*** Continual Learning
Four Types of Continual Learning: Look at [[./learnability-cl.org]] to find summaries of all the types (it also goes into more depth there).
** 3 Overview of the Proposed Method
*** Preliminary
Each task has a dedicated input space, label space, and training set. The class labels of the tasks are disjoint The goal of CIL is to learn a function $f : \cup_{t=1}^T X^{(t)} \rightarrow \cup_{t=1}^T Y^{(t)}$ which predicts the class label of each of the test samples.

From [[./cl-theoretical.org]] it was shown that the $\mathbf{P}(y_j^{(t)}) = \mathbf{P}(y_j^{(t)}|x,t)\mathbf{P}(t|x)$, where on the right hand side, the first probability notates the WP probability and the second probability notates the TP probability.
*** Overview of the Proposed TPL
This paper focuses on the second probability $\mathbf{P}(t|x)$

The mask based method in HAT is what is used to prevent CF. This is the main mask method, and more information can be found in [[./hat.org]] or [[./hat-cl.org]]

There are two main methods for task prediction with TPL, one for training and one for inference.

**** Training Methods
Instead of using the same supervised classifier that is in Hat, in TPL each task as an extra class called $O$, which represents the replay buffer of data for all the previous tasks. This allows for the head classifier to predict not only for the classes that exist for that task, but accurately predict for the other tasks the model is trained on.

The model has a feature extractor $h(x; \phi^{(t)})$ and a task-specific classifier $f(z;\theta^{(t)})$. The loss is taken as
$L(\theta(t), \phi(t)) = \mathbb{E}_{(x,y) \sim D(t) \cup \text{Buf}_{<t}} \big[ L_\text{CE}(f(h(x; \phi(t)); \theta(t)), y) \big] + L_\text{HAT}$

Breaking this down:
- $L(\theta(t), \phi(t))$: the loss for a given $\theta(t)$ and $\phi{(t)}$
- $\mathbb{E}_{(x,y) \sim D(t) \cup \text{Buf}_{<t}}$: a sample input and label from the distribution of the replay buffer where the task id is less than the current task
- $\big[ L_\text{CE}(f(h(x; \phi(t)); \theta(t)), y) \big]$: Cross entropy loss against class $y$ given $h(x;\phi(t))$ which is the feature extractor, and then
  $f(\ldots), \theta(t)$ which represents the task-specific classifier. Then that cross entropy loss is taken against the actual class $y$
- $L_\text{HAT}$: The regularization loss the HAT implements, look toward [[./hat.org]] for more about this

**** Testing (or inference)
In Testing, we use $\mathbf{P}(y_j^{(t)}) = \mathbf{P}(y_j^{(t)}|x,t)\mathbf{P}(t|x)$ to find the probability of the class. The WP probability is taken through a softmax of the original classes $Y^{(t)}$. The $O$ class is not used in inference as well. $P(y_j | x) = \big[softmax (f(h(x; \phi(t)); \theta(t)))\big]_{j} \cdot P(t|x)$. The class $y_j^{(t)}$ is the class that will be predicted.
** 4 Estimating Task-Id Prediction Probability
*** 4.1 Theoretical Analysis
TP probability ($\mathbf{P}(t|x)$) is given through the bernoulli classification of whether sample $x$ is from the distribution of task $t$ , or t's ($P_t$) complement $t^c$ ($P_{t^c}$).

In traditional OOD detection, the system does not see the OOD Distribution $P_{t^c}$, but only sees $P_t$. Instead they substitute $P_{t^c}$ with a uniform distribution, or some other distribution. This can lead to some failure points, as parts of the data can be encompassed by the uniform distribution or something.
**** Theorem 4.1
[[https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma][more info on neyman-pearson]]
Consider a test with hypothesis $H_0 : \theta = \theta_0$ (null hypothesis) and $H_1 : \theta = \theta_1$ (alternative hypothesis), the major idea is of this likelihood ratio test $\Lambda(x) = \frac{f_1(x)}{f_0(x)}$. That test is then applied to the probability of being part of $t$ or $t^c$. The rejection of $t$ comes if $\Lambda(x) > k$. Look to Appendix E for moe of the proof
**** Theorem 4.2
This test from Theorem 4.1 maximizes AUC (Area under the Curve) of binary classification between $P_t$ and $P_{t^c}$.
**** Good News for CIL
the IND distribution $P_t$ is just a distribution of that one task, however $P_{t^c}$ can actually be seen as a mixture of different distributions of the individual tasks through replay data($\{P_{X^{(t^*)}}\}_{t^* \ne t})$) which can then be used for CIL.
*** 4.2 Computing Task-Id Predicition Probability
1. estimating $P_t$ and $P_{t^c}$ using energy functions to compute likelihood ratio
2. Integrating Likelihood ratio with logit based score
3. Applying softmax function on all the scores to get the final probability
**** 4.2.1 Estimating $P_t$ and $P_{t^c}$ and Computing Likelihood Ratio
It is hard to estimate the data distribution for the raw image itself, so instead we look at estimation in the lower dimension feature space (this is the output of the backbone/HAT module). Additionally, you can use many distance based algorithms to understand IND density for the feature space (mahalonobis distance, KNN). The new method uses both KNN and Mahalanobis score to do the estimation.

The algorithm uses energy functions to parameterize $P_t$ and $P_{t^c}$. The probability density functions are $p_t(x) = \exp\{E_t(x)\}/Z_1$ and $p_{t^c}(x) = \exp\{E_{t^c}(x)\}/Z_2$ where $Z_1$ and $Z_2$ are normalization constants. This results in the likelihood ratio of
$S_\text{LR}(x) = \log\left(\frac{p_t(x)}{p_{tc}(x)}\right) = E_t(x) - E_{tc}(x) + \log\left(\frac{Z_2}{Z_1}\right)$, where because $\log\left(\frac{Z_2}{Z_1}\right)$ is a constant can be boiled down to $S_\text{LR}(x) = \log\left(\frac{p_t(x)}{p_{tc}(x)}\right) = E_t(x) - E_{tc}(x)$.

$S_\text{LR}^{(t)}(x) := \alpha \cdot S_\text{MD}^{(t)}(x) + d_{knn}(x,Buf_{t^c})$ ($\alpha$ is a hyper-paramter that makes the scores comparable).

***** Finding $E_t(x)$
Just use an OOD detection score $S_{MD}(x)$. This is the "inverse of the minimum Mahalanobis distance of feature $h(x;\phi^{(t)})$ to all class centroids. More in Appendix F.1
***** Finding $E_{t^c}(x)$
Use the replay data for estimation. $E_{t^c}(x) = -d_{KNN}(x,Buf_{t^c})$ where $d_{knn}(x,Buf_{t^c})$ is the k-nearest distances of the feature $h(x;\phi^{(t)})$ to the set of features in $Buf_{t^c}$. Basically this is just the distance the feature is from the rest of the conjugate tasks (specifically k-nearest distances).
***** Energy Functions
Energy functions are used to represent "complex relationships within data". For example the energy function $E(x,y)$ defines the relationship between $x$ and $y$ so that a lower energy means that state is more probable (a likely pairing of $x$ and $y$), whereas a higher energy means that state is less probable.
**** 4.2.2 Combining with a Logit Based Score
The $S_{LR}$ score is then combined with a logit-based score (the output of the heads for each of the features), $S_{logit}^{(t)}(\cdot)$. The ultimate composition of the two is
$E_{composition}(x) = \log\left(\exp\{\alpha_1 \cdot S_{logit}^{(t)}(x)\} + \exp\{\alpha_2 \cdot S_{LR}^{(t)}(x)\}\right)$. where $\alpha_1$ and $\alpha_2$ are scaling terms to make the scores comparable.

$S_{logit}^{(t)}(\cdot)$ is simply defined as the maximum logit of x.

The final $S_{TPL}^{(t)}(x)$ is as follows

$S_{TPL}^{(t)}(x) = \log\left(\exp\{\beta_1 \cdot S_{MLS}^{(t)}(x)\} + \exp\{\beta_2 \cdot S_{MD}^{(t)}(x) + d_{KNN}(x, {Buf}_{tc})\}\right)$. where $\beta_1$ and $\beta_2$ are scaling terms given by merging $\alpha$ from the first energy function and $\alpha_1$ and $\alpha_2$ from the second energy function. Because $d_{KNN}$ is closer to 1 than the rest, $\beta_1$ and $\beta_2$ are the inverse of the empirical means of the two scores.
*** 4.3 Converting Task-ID Predicition Scores to Probabilities
Just take the TPL energy scores and apply softmax on it (adding a temperature constant $\gamma$).

** 5 Experiments
*** 5.1 Experimental Setup
[[./images/tplp1.png]]
**** CIL Baselines
11 Replay Methods and 6 non-replay methods. The primary method is $HAT_{CIL}$ which adapts HAT for CIL methods.
**** Datasets
Split is basically the same as [[./cl-theoretical.org]]
**** Backbone Architectures
Two sets of experiments are done, one with a pre-trained model, and one without a pre-trained model. TLP uses the DeiT-S/16 model pretrained without the ImageNet data.
*** 5.2 Results and Comparisons
CIL accuracy shows that TPL performs basically the best with and without pretraining
*** 5.3 Ablation Study
**** Different $E_t$ vs $E_{t^c}$
The ablation shows that the $P_{t^c}$ distribution is better than a uniform distribution. Additionally, even though the KNN may outperform the MD method, it is still better to be used for the $P_t$ distribution, because it does not need to have all the data available.
**** Different logit-based scores
MSP, MLS, and EBO are considered, EBO and MLS were comparable, but MLS (maximum logit score) still performed the best. MSP was not comparable.
**** Smaller replay buffer size
The performance drop when using a smaller replay buffer size is small, and TPL is robust to using smaller replay sizes
**** More OOD methods
1. There is a linear relationship between OOD detection AUC and CIL ACC performances (the area under the curve of binary classification between $P_t$ and $P_{t^c}$)
2. Different OOD methods have similar TIL when applying hat (just can't do OOD properly)
**** More pre-trained models
The method is extensible to other pretrained models (MAE, Dino, ViT, and DeiT)
** Conclusion
Traditional OOD does not work very well for CIl, and TPL outperforms strong baselines and has very little catastrophic forgetting
